// utils/stt/metrics.ts
import Levenshtein from "js-levenshtein";

/**
 * í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬: êµ¬ë‘ì  ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
 * CER/WER ê³„ì‚° ì „ì— í˜¸ì¶œí•˜ì—¬ ê³µì •í•œ ë¹„êµë¥¼ ìœ„í•´ ì‚¬ìš©
 */
function normalizeText(text: string): string {
  return text
    // êµ¬ë‘ì  ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
    .replace(/[.,!?;:'""`~@#$%^&*()[\]{}<>\/\\|_+=\-â€”â€“â€¦Â·â€¢Â°]+/g, "")
    // ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    .replace(/\s+/g, " ")
    // ì•ë’¤ ê³µë°± ì œê±°
    .trim();
}

/**
 * Normalized Character Error Rate (CER) ê³„ì‚°
 * ë¬¸ì ë‹¨ìœ„ ì˜¤ë¥˜ìœ¨ (0% ~ 100% ë²”ìœ„ë¡œ ì •ê·œí™”)
 *
 * ê³µì‹: Normalized CER = (S + D + I) / (S + D + I + C)
 *       = distance / max(len(ref), len(hyp))
 *
 * - S: Substitutions (ì¹˜í™˜)
 * - D: Deletions (ì‚­ì œ)
 * - I: Insertions (ì‚½ì…)
 * - C: Correct (ì˜¬ë°”ë¥¸ ë¬¸ì)
 */
export function calculateCER(reference: string, hypothesis: string): number {
  if (!reference) return 0;

  // ì „ì²˜ë¦¬: êµ¬ë‘ì  ì œê±° í›„ ê³µë°± ì œê±°
  const refChars = normalizeText(reference).replace(/\s+/g, "");
  const hypChars = normalizeText(hypothesis).replace(/\s+/g, "");

  if (refChars.length === 0) return 0;

  // ì¸ì‹ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° (ë¹ˆ ë¬¸ìì—´) â†’ CER 100%
  if (hypChars.length === 0) {
    console.log(`[CER] Reference: "${refChars}" (${refChars.length}ì)`);
    console.log(`[CER] Hypothesis: (ë¹ˆ ë¬¸ìì—´) - ì¸ì‹ ê²°ê³¼ ì—†ìŒ`);
    console.log(`[CER] âš ï¸ ì¸ì‹ ê²°ê³¼ ì—†ìŒ â†’ Normalized CER: 100%`);
    return 1.0;
  }

  const distance = Levenshtein(hypChars, refChars);

  // Normalized CER: í•­ìƒ 0~1 ë²”ìœ„ ë³´ì¥
  // (S+D+I) / (S+D+I+C) = distance / max(len(ref), len(hyp))
  const maxLen = Math.max(refChars.length, hypChars.length);
  const normalizedCer = distance / maxLen;

  console.log(`[CER] Reference: "${refChars}" (${refChars.length}ì)`);
  console.log(`[CER] Hypothesis: "${hypChars}" (${hypChars.length}ì)`);
  console.log(`[CER] Distance: ${distance}, Max Length: ${maxLen}`);
  console.log(`[CER] Normalized CER: ${(normalizedCer * 100).toFixed(1)}%`);

  return normalizedCer;
}

/**
 * Normalized Word Error Rate (WER) ê³„ì‚°
 * ë‹¨ì–´ ë‹¨ìœ„ ì˜¤ë¥˜ìœ¨ (0% ~ 100% ë²”ìœ„ë¡œ ì •ê·œí™”)
 *
 * ê³µì‹: Normalized WER = (S + D + I) / (S + D + I + C)
 *       = distance / max(len(ref), len(hyp))
 *
 * - S: Substitutions (ì¹˜í™˜)
 * - D: Deletions (ì‚­ì œ)
 * - I: Insertions (ì‚½ì…)
 * - C: Correct (ì˜¬ë°”ë¥¸ ë‹¨ì–´)
 */
export function calculateWER(reference: string, hypothesis: string): number {
  if (!reference || reference.trim().length === 0) return 0;

  // ì „ì²˜ë¦¬: êµ¬ë‘ì  ì œê±° í›„ ë‹¨ì–´ ë¶„ë¦¬
  const normalizedRef = normalizeText(reference);
  const normalizedHyp = normalizeText(hypothesis);

  if (normalizedRef.length === 0) return 0;

  const refWords = normalizedRef.split(/\s+/);

  // ì¸ì‹ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° (ë¹ˆ ë¬¸ìì—´) â†’ WER 100%
  if (normalizedHyp.length === 0) {
    console.log(
      `[WER] Reference: "${refWords.join(" ")}" (${refWords.length}ë‹¨ì–´)`
    );
    console.log(`[WER] Hypothesis: (ë¹ˆ ë¬¸ìì—´) - ì¸ì‹ ê²°ê³¼ ì—†ìŒ`);
    console.log(`[WER] âš ï¸ ì¸ì‹ ê²°ê³¼ ì—†ìŒ â†’ Normalized WER: 100%`);
    return 1.0;
  }

  const hypWords = normalizedHyp.split(/\s+/);

  const n = refWords.length;
  const m = hypWords.length;

  if (n === 0) return 0;

  // DP í…Œì´ë¸” ì´ˆê¸°í™”
  const d: number[][] = Array.from({ length: n + 1 }, () =>
    new Array(m + 1).fill(0)
  );

  for (let i = 0; i <= n; i++) {
    d[i][0] = i;
  }
  for (let j = 0; j <= m; j++) {
    d[0][j] = j;
  }

  for (let i = 1; i <= n; i++) {
    for (let j = 1; j <= m; j++) {
      if (refWords[i - 1] === hypWords[j - 1]) {
        d[i][j] = d[i - 1][j - 1];
      } else {
        d[i][j] = Math.min(
          d[i - 1][j] + 1, // ì‚­ì œ
          d[i][j - 1] + 1, // ì‚½ì…
          d[i - 1][j - 1] + 1 // ì¹˜í™˜
        );
      }
    }
  }

  const distance = d[n][m];

  // Normalized WER: í•­ìƒ 0~1 ë²”ìœ„ ë³´ì¥
  // (S+D+I) / (S+D+I+C) = distance / max(len(ref), len(hyp))
  const maxLen = Math.max(n, m);
  const normalizedWer = distance / maxLen;

  console.log(
    `[WER] Reference: "${refWords.join(" ")}" (${refWords.length}ë‹¨ì–´)`
  );
  console.log(
    `[WER] Hypothesis: "${hypWords.join(" ")}" (${hypWords.length}ë‹¨ì–´)`
  );
  console.log(`[WER] Distance: ${distance}, Max Length: ${maxLen}`);
  console.log(`[WER] Normalized WER: ${(normalizedWer * 100).toFixed(1)}%`);

  return normalizedWer;
}

/**
 * ìµœì¢… ì ìˆ˜ ê³„ì‚° íŒŒë¼ë¯¸í„°
 */
export interface FinalScoreParams {
  // ë°œìŒ ì ìˆ˜ (ONNX CER)
  tau?: number; // ë°ë“œì¡´ (ê¸°ë³¸ê°’: 0.05)
  alpha?: number; // ë¯¼ê°ë„ (ê¸°ë³¸ê°’: 3.0)
  gamma?: number; // ê³¡ì„  í˜•íƒœ (ê¸°ë³¸ê°’: 0.9)
  // ì˜ë¯¸ ì „ë‹¬ ì ìˆ˜ (NLP WER)
  tauW?: number; // ë°ë“œì¡´ (ê¸°ë³¸ê°’: 0.10)
  beta?: number; // ë¯¼ê°ë„ (ê¸°ë³¸ê°’: 1.5)
  delta?: number; // ê³¡ì„  í˜•íƒœ (ê¸°ë³¸ê°’: 1.0)
  // ì‹¬ê°ë„ íŒ¨ë„í‹° (NLP CER)
  tauP?: number; // ë°ë“œì¡´ (ê¸°ë³¸ê°’: 0.08)
  lambda?: number; // ë¯¼ê°ë„ (ê¸°ë³¸ê°’: 2.5)
  epsilon?: number; // ê³¡ì„  í˜•íƒœ (ê¸°ë³¸ê°’: 1.0)
  // ê°€ì¤‘ì¹˜
  w1?: number; // ë°œìŒ ë¹„ì¤‘ (ê¸°ë³¸ê°’: 0.60)
  w2?: number; // ì˜ë¯¸ ë¹„ì¤‘ (ê¸°ë³¸ê°’: 0.25)
  w3?: number; // íŒ¨ë„í‹° ë¹„ì¤‘ (ê¸°ë³¸ê°’: 0.15)
}

/**
 * ë‚œì´ë„ í”„ë¦¬ì…‹
 */
export const DIFFICULTY_PRESETS: Record<string, FinalScoreParams> = {
  easy: {
    alpha: 1.0,
    lambda: 1.5,
    w1: 0.5,
    w2: 0.35,
    w3: 0.15,
  },
  normal: {
    alpha: 1.5,
    lambda: 2.5,
    w1: 0.6,
    w2: 0.25,
    w3: 0.15,
  },
  hard: {
    alpha: 2.0,
    lambda: 4.0,
    w1: 0.55,
    w2: 0.2,
    w3: 0.25,
  },
};

/**
 * ìµœì¢… ì ìˆ˜ ê³„ì‚° (NLP CER íŒ¨ë„í‹° í¬í•¨) - ê³±ì…ˆ ë°©ì‹ íŒ¨ë„í‹°
 *
 * ê³µì‹:
 * - ë°œìŒ ì ìˆ˜: score_pronunciation = max(0, 1 - Î± * CER'_raw)^Î³
 * - ì˜ë¯¸ ì „ë‹¬: score_semantic = max(0, 1 - Î² * WER'_nlp)^Î´
 * - ì‹¬ê°ë„ íŒ¨ë„í‹°: penalty_severity = max(0, 1 - Î» * CER'_nlp)^Îµ (ê³±ì…ˆ ë°©ì‹)
 * - ê¸°ë³¸ ì ìˆ˜: baseScore = (w1 Ã— score_pronunciation + w2 Ã— score_semantic) / (w1 + w2)
 * - ìµœì¢…: FinalScore = 100 Ã— baseScore Ã— penalty_severity
 *
 * ì‹¬ê°ë„ íŒ¨ë„í‹°ëŠ” ê³±ì…ˆ ë°©ì‹ìœ¼ë¡œ ì ìš©:
 * - ì•„ì˜ˆ í‹€ë¦° ê²½ìš° (penalty = 0) â†’ ìµœì¢… ì ìˆ˜ 0ì 
 * - ì •ìƒì ì¸ ê²½ìš° (penalty â‰ˆ 1) â†’ ê¸°ë³¸ ì ìˆ˜ ê·¸ëŒ€ë¡œ
 *
 * @param onnxCer - ONNX ëª¨ë¸ ê¸°ë°˜ CER (ë°œìŒ ê·¸ëŒ€ë¡œ, 0~1)
 * @param nlpCer - NLP STT ê¸°ë°˜ CER (ë¬¸ë§¥ êµì •ë¨, 0~1)
 * @param nlpWer - NLP STT ê¸°ë°˜ WER (ë¬¸ë§¥ êµì •ë¨, 0~1)
 * @param params - íŒŒë¼ë¯¸í„° (ì˜µì…˜)
 * @returns 0~100 ì‚¬ì´ì˜ ìµœì¢… ì ìˆ˜
 */
export function calculateFinalScore(
  onnxCer: number,
  nlpCer: number,
  nlpWer: number,
  params: FinalScoreParams = {}
): number {
  // ê¸°ë³¸ê°’ ì„¤ì •
  const {
    // ë°œìŒ ì ìˆ˜ íŒŒë¼ë¯¸í„°
    tau = 0.05,
    alpha = 1.5,
    gamma = 0.9,
    // ì˜ë¯¸ ì „ë‹¬ ì ìˆ˜ íŒŒë¼ë¯¸í„°
    tauW = 0.1,
    beta = 1.5,
    delta = 1.0,
    // ì‹¬ê°ë„ íŒ¨ë„í‹° íŒŒë¼ë¯¸í„°
    tauP = 0.08,
    lambda = 2.5,
    epsilon = 1.0,
    // ê°€ì¤‘ì¹˜
    w1 = 0.6,
    w2 = 0.25,
    w3 = 0.15, // w3ëŠ” ì´ì œ ì‚¬ìš©ë˜ì§€ ì•Šì§€ë§Œ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
  } = params;

  // Step 1: ë°œìŒ ì ìˆ˜ (ONNX CER ê¸°ë°˜)
  const cerRawPrime = Math.max(0, onnxCer - tau);
  const scorePronunciation = Math.pow(Math.max(0, 1 - alpha * cerRawPrime), gamma);

  // Step 2: ì˜ë¯¸ ì „ë‹¬ ì ìˆ˜ (NLP WER ê¸°ë°˜)
  const werNlpPrime = Math.max(0, nlpWer - tauW);
  const scoreSemantic = Math.pow(Math.max(0, 1 - beta * werNlpPrime), delta);

  // Step 3: ì‹¬ê°ë„ íŒ¨ë„í‹° (NLP CER ê¸°ë°˜) - ì•„ì˜ˆ í‹€ë ¸ì„ ë•Œë§Œ 0ì  ì²˜ë¦¬ìš©
  const cerNlpPrime = Math.max(0, nlpCer - tauP);
  const penaltySeverity = Math.pow(Math.max(0, 1 - lambda * cerNlpPrime), epsilon);

  // Step 4: ê¸°ë³¸ ì ìˆ˜ ê³„ì‚° (w1, w2 ì •ê·œí™”)
  const totalWeight = w1 + w2;
  const baseScore =
    (w1 * scorePronunciation + w2 * scoreSemantic) / totalWeight;

  // Step 5: ìµœì¢… ì ìˆ˜ (ê³±ì…ˆ ë°©ì‹ íŒ¨ë„í‹° ì ìš©)
  // ì•„ì˜ˆ í‹€ë¦° ê²½ìš°ì—ë§Œ 0ì  ì²˜ë¦¬, ê·¸ ì™¸ì—ëŠ” ê¸°ë³¸ ì ìˆ˜ ìœ ì§€
  const finalScore = 100 * baseScore * penaltySeverity;

  console.log("========================================");
  console.log("[FinalScore] ğŸ† ìµœì¢… ì ìˆ˜ ê³„ì‚°");
  console.log(`  ì…ë ¥ê°’:`);
  console.log(`    - ONNX CER: ${(onnxCer * 100).toFixed(1)}%`);
  console.log(`    - NLP CER: ${(nlpCer * 100).toFixed(1)}%`);
  console.log(`    - NLP WER: ${(nlpWer * 100).toFixed(1)}%`);
  console.log(`  ì¤‘ê°„ ì ìˆ˜:`);
  console.log(`    - ë°œìŒ ì ìˆ˜: ${(scorePronunciation * 100).toFixed(1)}%`);
  console.log(`    - ì˜ë¯¸ ì „ë‹¬: ${(scoreSemantic * 100).toFixed(1)}%`);
  console.log(`    - ê¸°ë³¸ ì ìˆ˜: ${(baseScore * 100).toFixed(1)}%`);
  console.log(`    - ì‹¬ê°ë„ íŒ¨ë„í‹° (ê³±ì…ˆ): ${(penaltySeverity * 100).toFixed(1)}%`);
  console.log(`  ìµœì¢… ì ìˆ˜: ${finalScore.toFixed(1)}ì `);
  console.log("========================================");

  return Math.round(finalScore);
}
